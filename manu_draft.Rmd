---
title: "The importance of open science for biological assessment"
output: 
  bookdown::word_document2:
    reference_docx: my_styles.docx
bibliography: refs.bib
author: 'Marcus W. Beck (marcusb@sccwrp.org), Raphael D. Mazor (raphaelm@sccwrp.org), Susanna T. Theroux (susannat@sccwrp.org)'
urlcolor: blue
link-citations: true
---

```{r setup, echo = F, warning = F, message = F, results = 'hide'}
# figure path, chunk options
knitr::opts_chunk$set(fig.path = 'figs/', warning = F, message = F, echo = F, cache = T, dev.args = list(family = 'serif'), dpi = 300, warning = F, cache.path = 'manu_draft_cache/',
  fig.process = function(x) {
  x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
  if (file.rename(x, x2)) x2 else x
  })

# libraries
library(Jabbrev)

# extract bib entries from online
bib_scrp('manu_draft.Rmd', 'refs.bib')

```

```{r echo = F, cache = F}
raw <- system('git log -1', intern = TRUE)
raw <- raw[grep('^Date', raw)]
raw <- paste('Version', raw)
```
`r raw`

# Abstract 

Open science principles that seek to democratize science can effectively bridge the gap between researchers and environmental managers, yet widespread adoption has yet to gain traction for the development and appplication of bioassessment methods.  At the core of this philosophy is the concept that research should be reproducible and transparent, in addition to having long-term provenance through effective modes of data preservation and sharing.  We discuss core open science concepts that have been advocated more generally in the ecological sciences and will emphasize how adoption can benefit bioassessment for both prescriptive condition assessments and proactive applications that inform planning activities.  Examples from the state of California will be used to demonstrate effective adoption of open science principles through data stewardship, reproducible research, and engagement of stakeholders with multimedia applications.  Technical, sociocultural, and institutional challenges for adopting open science will also be discussed, including practical approaches for overcoming these hurdles in bioassessment applications.

# Introduction

Bioassessment is an essential element of aquatic monitoring programs that establishes a foundation of decisions for managing the ecological integrity of environmental resources.  Legal mandates to assess biological condition have set a precedent for developing bioassessment methods in the United States (Clean Water Act, CWA), Canada (Canada Waters Act), and Europe (Water Framework Directive).  Decades of research to meet these mandates have supported the development of methods for multiple assemblages with regional applications in streams, rivers, lakes, and marine environments [@Karr86;@Kerans94;@Fore02;@Beck09;@Borja09].  This body of applied tools represents substantial progress in understanding how biological organisms can be used as accurate and interpretable sentinels of environmental condition.  Monitoring programs in the United States and internationally have collected millions of records of biological data spanning decades and hundreds of assessment methods have been developed from these data. The explicit link to environmental management distinguishes bioassessment from basic ecological research.  Although bioassessment can and has been used to inform basic research, the intended use of these tools is to inform the protection and restoration of ecological integrity.  

Bioassessment products will have limited use if they do not meet the needs of management and regulatory communities [@Bain00; @Stein09; @Kuehne17].  In the United States, the CWA gives power to states, tribes, and territories for method development, which in turn requires federal approval to be implemented in a regulatory framework(e.g., Total Maximum Daily Load reporting, stormwater permitting). An imbalance exists between the developed methods and those that are approved for regulatory use.  A recent review of assessment methods for ecological integrity in the US showed that few were explicitly connected to freshwater policy [@Kuehne17].  Of those methods that are actively used, a more problematic issue is the manner of application within standard regulatory frameworks.  Biological indices are typically used to develop post-hoc diagnoses to trigger remediative or restoration actions, or serve as early warning indicators of environmental change [@Niemi04].  A critical concern is that these tools, although technically sound, are implicitly being used to document the long-term demise of environmental health.  A much broader use for bioassessment to guide planning activities, such as identifying conservation priorities [@Linke11;@Howard18], could extend the reach of bioassessment products beyond regulatory applications.

An effective bioassessment product must jointly address the technical challenges of developing a diagnostic index and the implementation challenges of using an index to address the needs of environmental managers and regulators [@Jackson94;@Dale01]. For decades, research in the bioassessment community has focused on addressing the former. Substantial technical advances have been made in predicting biological responses to environmental change, how these responses can be distinguished from natural environmental variation, and determining the impacts of these changes.  Standardized protocols have also been developed [@McDonald04;@Stoddard08].  Many bioassessment indices are characterized as either multimetric, such as an index of biotic integrity [@Karr86], or multivariate where condition is based on predictive methods that evaluate similarity of taxonomic composition to reference expectations.  The reference-condition approach establishes the foundation for many bioassessment methods whereby a set of reference sites are identified and used to evaluate levels of biological deviation to define potential impacts [@Reynoldson97;@Stoddard06]. Most indices can be broadly categorized in the context of these well-established technical methods.

Implementation challenges have severely limited the use of bioassessment products in management and regulatory applications relative to the availability of developed methods.  Characterizing how an index could be used in practice to inform decisions and prioritize management actions is often opaque relative to why an index may have been originally developed. Hundreds of assessment methods have been developed for specific regional applcations [@Birk12] and concerns about redundancy, comparability, duplicated effort, and lack of coordinated monitoring have recently been discussed within the research community [@Cao11;@Poikane14;@Kelly16;@Nichols16]. Moreover, existing methods may not be discoverable beyond immediate research applications [@Hering10;@Nichols16] or may be incorrectly applied based on differences between goals for developing an index and the needs of management programs [@Dale01;@Stein09].  The abundance of available methods can be a point of frustration for managers given a lack of guidance for choosing an appropriate method among alternatives, particularly as to how a method may relate to specific management, monitoring, or policy objectives [@Dale01;@Stein09].  

Environmental managers require additional tools that transform bioassessment data and methods into actionable information.  A new mode of operation is needed where method development is open and transparent, developed products are discoverable and reproducible, and most importantly, implementation in the management community is intuitive and purposeful.  Open science principles that can democratize all aspects of the scientific method can meet these needs, yet bioassessment research and its application to better serve the environment has not fully embraced these principles. Others have advocated more broadly for inclusion of open science principles in the ecological sciences [@Hampton15;@Hampton16;@Lowndes17] and a growing wave of momentum has influenced how scientists conceptualize research in other disciplines (e.g., archeaology, @Marwick16; behavioral ecology, @Ihle17; vegetation sciences, @Collins16).  Adopting an open science paradigm in biaossessment is particularly relevant compared to other fields given the explicit need to develop tools that are open and accessible to the management community. Legal and ethical precedents in bioassessment may also necessitate the open sharing of data given that environmental monitoring programs are often publicly funded.

This review will demonstrate tools and approaches for open science, which will empower the research and management community to embrace a new mode of thinking for bioassessment applications. These approaches are expected to benefit the research community by augmenting existing workflows for developing assessment tools, but more importantly, improve the ability of these methods to address environmental issues by bridging the gap between the scientific, management, and regulatory communities. An overview of the general principles of open science is provided, followed by a discussion of specific benefits and how these principles can be applied to bioassessment.  We use examples from the state of California to demonstrate how existing tools can be tailored to address legislative mandates for free and open sharing of data, especially by directly engaging stakeholders that require practical approaches for using bioassessment tools in planning activities.  We conclude with a discussion of technical, sociocultural, and instutional hurdles that have, thus far, prevented widespread adoption of open science and provide recommendations for the bioassessment community to address these challenges.

# Principles of open science

Conventional modes of creating scientific products and more contemporary approaches that align with open science principles share the same goals.  Both are motivated by guiding principles of the scientific method that make the process of discovery transparent and repeatable. Where the conventional and open science approaches diverge is the extent to which technological advances are leveraged as instrumental tools that facilitate the entire research process.  Distinction between the two approaches can be conceptualized as the "paper as the only and final product" for the conventional approach, whereas the open science approach is inherently linked to advances in communication and analysis that have been facilitated by the Internet and computer sciences.  As a result, the open science approach can enhance all aspects of the scientific process from initial conception of a research idea to the delivery and longevity of a research product (Figure \@ref(fig:basicflow)).  The process is iterative where products are improved by the individual and/or others, facilitated by open science tools that enhance access and reproducibility of data.

The paradigm of the scientific paper as a final research product can inhibit forward progress for several reasons, particularly so in the applied sciences.  The research paper is conventially viewed as a communication tool for scientists to report and share results among peers.  Researchers access periodicals to stay informed of scientific advances and use the information to replicate methods for follow-up analysis.  Although the primary literature continues to provide these fundamental services, this workflow is problematic when scientific products are needed to serve interests outside of the research community.  For example, the paper as an endpoint for environmental managers fails to deliver tools that are easily accessible from the practitioners perspective, both in application and interpretation.  A research paper rarely affects environmental change because it does not provide a mechanism to transfer actionable information to those that require scientific guidance for decision-making. Numerous studies have documented implementation failures as a result of siloing among research communities where the flow of information does not extend beyond institutional walls.  The loss of information over time that intimately describes a research product is another well-known flaw associated with the paradigm of research paper as final product [@Michener97].

The open science approach makes the researcher a steward of their data. This allows the data to be treated as a living product with a history, rather than proprietary and serving only the internal needs of an immediate research goal. Data can be generically described as any component of the research process that is used to address a research goal and could include literal tabular data, a laboratory notebook, a research report, data visualizations or maps, analysis code or software, or even presentation materials.  Open science principles can be applied to any and all of these data with the end goal of facilitating communication for researchers and those for which the research was developed [@BondLamberty16]. These tools also benefit the individual researcher by providing information for the "future-self" to recreate a past working environment. In all cases, the data are openly accessible and documented for reproducibility and discovery using technologies that facilitate communication and sharing.  

Open data can benefit research by contributing to an increase in novel products created through collaboration.  Collaborative publications have increased in the environmental sciences as researchers leverage open data to create synthesis products as the sum of individual datasets. Quantitative meta-analyses and systematic reviews are increasingly used to extract information from the primary literature [@Lortie14].  In addition, open data products can increase efficiency of the individual researcher and a collective research team by encouraging collaborators to adopt an open science workflow.  Many tools developed within the software and computer science community are now easily accessible to environmental scientists that can be used to create open data.  Version control software (e.g, Git, GitHub), open source programming languagues (e.g, R), and integrated development environments (IDEs, e.g., RStudio) can all be leveraged by applied ecologists to dynamically create and share open data products that build instutional memory.  These tools promote deliberate and shared workflows among researchers that can lead to better science in less time [@Lowndes17].

Open and unfettered access to data can also benefit management and regulatory communities.  Although many monitoring datasets are publicly available, the data quality, level of documentation, and ease of use varies widely.  This can create research and implementation challenges as datasets may be difficult to locate, contexts for data may be misunderstood, and data from different sources require synthesis.  Many open science tools can improve the accessibility of data from monitoring programs by establishing workflows for data synthesis and discovery, often through the adoption of a common metadata structure (e.g., Ecological Metadata Language Standard) and integration of data within federated data networks (e.g., DataONE).  Open data maintained by management or regulatory communities benefits the research community, which in turn benefits the data maintainers that require scientific products to inform decisions.  Open data can also improve public trust in scientific findings by exposing the underlying information used to develop a research product [@Grand12].  Increased trust could facilitate eventual adoption of proposed rules or regulations that are based on research products created from open data.

# Applying open science principles to bioassessment

Here we provide a detailed description of science tools that the bioassessment community could leverage to adopt a a philosophy of creating reproducible, transparent, and discoverable research products for environmental managers.  To emphasize the value that each of these tools can have for specific steps of the scientific process, we first describe a "conventional" workflow, which is then constrasted with a workflow that adopts open science tools.  In both cases, the technical and implementatation phases of a bioassessment product are acknowledged as distinct steps of analysis that describe the entire process from idea conception to adoption in management or regulatory applications.  We use this paradigm to jointly demonstrate how open science tools can be applied beyond the research phase, but also reinforce the concept that a bioassessment product is only as relevant as its applied context (i.e., an index will not have value if its final home is the primary literature).

## Closed science

First we consider a hypothetical workflow for how many bioassessment products are potentially created (Figure \@ref(fig:closedopen)a).  Research goals are identified through legislative requirements to assess biological integrity of navigable surface waters.  In the United States, this need originates at the state-level where regulatory institutions require robust bioassessment methods.  Historically, a regulatory agency may not have ownership of the data required for index development, as for states that separately manage pollutants (e.g., stormwater or discharge permits) and natural resources (e.g., fisheries).  The required data may be decentralized across public and private institutions. The task of identifying, gathering, and synthesizing these data may be contracted by the state regulatory agency to a third party, such as a private consultant or an academic institution.  This separation between consumers and creators of bioassessment products can be an initial cause of implementation challenges as research agendas may diverge with communication barriers between institutions.  

A typical workflow for developing an index is not entirely dissimilar from a conventional scientific process.  The primary investigator begins by identifying the research goal, developing methods to achieve that goal, and then identifying the data needs and analyses based on the existing sciencd.  Development of a bioassessment index is not explicitly hypothesis-driven, in that an index is not meant to support or refute an academic question, but rather it is implicitly guided by the needs of an ecological condition assessment.  The index must predict biological responses to environmental change relative to natural variation and the relative impacts of these changes should be quantifiable.  As noted above, standard procedures that address these technical challenges have generally been accepted by the research community as robust and index development could be considered more procedural than research-oriented.  This can contribute to a relaxation of scientific principles that reinforce reproducibility and attention to detail if the development process is viewed more as a recipe than a formal research endeavor.  

Inadequate documentation of data sources, what data were used, and how data were synthesized can also contribute to implementation challenges in conventional workflows.  Ideally, a dataset from a regional monitoring program would be available that covers the range of natural variability and relevant stressor gradients.  If so, the origin can easily be identified after the product is developed and others will more easily be able to recreate or refine as needed.  However, a pre-existing monitoring program may not have goals that align with the needs of a bioassessment product.  The data may also have limitations that affect performance or even prevent their use entirely for assessment.  For example, a fisheries monitoring program may only sample select locations and may have inadequate coverage of aquatic biodiversity.  In these scenarios, supplementary data must be gathered from other sources, all of which potentially have different goals for originally collecting the data.  The end product is a synthesized dataset that is wrangled to meet the requirements of a bioassessment product, but its origin and workflow to achieve the necessary format may be unknown except to the individual that compiled the data.  This creates significant challenges for future products or policies that depend on the product and may even erode institutional trust if the provenance of the dataset is unknown. 

Finally, most bioassessment workflows usually lack tools for calculation and interpretation of results.  Although the availability and need for documentation of the raw data is important, insufficient resources to facilitate use by managers and policy-makers, both in calculation and interpretation, represents the primary limitation of bioassessment effectiveness with conventional workflows.  The worst case scenario is a spreadsheet-oriented approach to converting raw data into a synthesized index.  Not only is this a major challenge for the researcher that develops the index, but it prevents others from applying the tool to reproduce the results and apply it with novel data.  There are many reasons for these challenges (e.g., lack of documentation, unknown data requirements, no interpretation guidance), but the fundamental issue is inaccessibility of the product. A management or regulatory agency will have no ability to interpret these data and the final product will not pass independent review if others cannot recreate the results.  

## Using open science tools to enhance bioassessment

The above example is an extreme hypothetical case where bioassessment products fail to affect any positive change in environmental management due to a complete deficiency in openness and failed implementation as a result.  Many bioassessment methods can be described more positively, yet the research community could benefit from adopting a more open approach to creating and delivering assessment tools.  This approach is particularly relevant from the perspective of implementation and science translation, as all modes of communication between research, managers, and regulators could be enhanced with open science.  The following section describes key components of the open science process that can faciliate the development and implementation of bioassessment products for affecting positive environmental change.  We focus specifically on open science applications for data provenance, method development, and method delivery.    

The overall process is shown in Figure \@ref(fig:closedopen)b as an expansion of general concepts in Figure \@ref(fig:basicflow), with a specific science translation phase for implementation.  The critical difference of this open approach with the closed scenario in Figure \@ref(fig:closedopen)a is the iterative flow of ideas and products between the management community and stakeholders, the researcher developing the bioassessment product, and the broader community that provides data and guidance documents in the primary and secondary literature.  This iterative flow of information is facilitated by 1) openly sharing planning documents, 2) using established metadata standards to document synthesized data products, 3) hosting data products on open repositories, 4) creating reproducible summary documents that integrate the data and research products, and 5) incorporating the developed product into interactive applications that deliver the results to the stakeholders.  The technical phase of defining research goals, collecting and synthesizing data, and developing the bioassessment product remains the sole responsibility of the researcher.  However, the process is distinguished by the flow of information to and from the research phase that can benefit the specific project and the science of bioassessment as a whole.

### Developing bioassessment goals

In an open science paradigm, the goals identified by the researcher for developing a bioassessment product should occur through close interaction with the management or regulatory institution that requires the product.  Establishing goals should occur through a two-way exchange of information where the regulatory institution communicates the assessment needs of a bioassessment product that reflects both legislative reporting requirements and stakeholder concerns.  The researcher developing the bioassessment product should recognize these needs while also considering the potential balance between the goals and limitations of the data or state of the science to meet these goals.  This two-way exchange of information can be accomplished through direct communication and sharing planning documents to ensure all decisions are transparent.  In person meetings are ideal, but planning documents are dynamic and will require remote sharing and revision as ideas progress.  Online tools such as Google documents, Slack discussion channels, and open lab notebooks can be instrumental for collaboration. More informal approaches, such as blogging and sharing ideas on social media, can expose new concepts to the broader community for guidance.  Overall, the iterative exchange of information for identifying goals will ensure that the needs of the management and stakeholder communities will be consistent with the services provided by the research product.  

### Curating bioassessment data

After the goals are established, the researcher identifies requirements and sources of data that need to be synthesized to meet the research needs.  Under a closed scenario, data flows one way from the source to the researcher and is used only as a means to create the final research product.  In the open scenario, the data itself is a product to achieve the research goals and also becomes available to the research and management community as a fully documented source of information that can be leveraged beyond the specific project.  The openness of the synthesized data product is one of the primary means of facilitating the implementation phase of a bioassessment product.  The synthesized data product can be used by the individual researcher to create interactive applications for stakeholders to share and explore the data and is also fully integrated into summary reports using software for generating dynamic documents (e.g, Sweave, RMarkdown, @Allaire18). The data product also becomes available on an open data repository that is discoverable by other researchers and can contribute to alternative scientific advances beyond the immediate goals. 

A bioassessment researcher operating under an open science paradigm has the responsibility of curating the data from its initial creation to its final home in an open repository.  This responsibility is particularly relevant given that a synthesized dataset can originate from multiple sources and the created output can be indistinguishable from the original data.  For example, a multimetric index may require taxonomic data collected at multiple sites by different institutions, whereas the output data may include summary scores, individual metrics, and any additional supporting information to assess the quality of the output. This requires use of a standardized metadata language (e.g., the Ecological Metadata Language or EML) to document the who, what, and why of a particular dataset.  Adoption of a metadata standard also ensures that a machine-readable file is produced to allow integration into a data repository.  This will allow a synthesized data product to be discoverable beyond the specific research application and will include the metadata to understand the context of the data.  Finally, a dataset can be assigned a unique digial object identifier (e.g., through Zenodo) that provides a permanent address and is also citable to allow researchers to track usage of a bioassessment data product.  

### Using R for bioassessment translation

The most important process of the open science workflow is the translation of bioassessment products to the management and regulatory community.  This process should be fundamentally linked to open source analysis and development tools that can be used to deliver the products using a reproducible and accessible platform.  In particular, the popularity of the R statistical programming language [@RDCT18] has increased in the last ten years and is the most commonly used analysis platform in the environmental sciences.  This software provides thousands of user contributed packages and is also a programming language that can be used to create specific analysis workflows.  The availability of existing packages and the ability to create new packages is a strength of R that is under-utilized by the bioassessment community.  An assessment index packaged in R can automate the tedious process of converting raw taxonomic data to summary scores.  An R package is also modular, meaning it includes all necessary analyses, data, and documentation to allow use by others.  This modularity is critical for reaching management and stakeholder communities by providing a tool that focuses entirely on understanding the relevance of the output and not the technical details that are less important for decision-making.    

Several existing R packages have value for the bioassessment community.  For managing the day to day tasks of working with multiple datasets, the tidyverse suite of packages provides the necessary tools to import, wrangle, explore, and plot almost any data type.  These packages are developed around the concept of "tidy" data that provide a common and natural framework for working with data [@Wickham14c].  These principles have importance for bioassessment where the synthesized datasets used to create a product should be logically structured to facilitate use by others.  Although the time and effort required to produce a tidy dataset can seem excessive relative to native formats (e.g., raw sample data), downstream analyses will be greatly facilitated.  The tidyverse also includes the popular ggplot2 package that is based on a syntactical grammar of graphics for plotting [@Wilkinson05;@Wickham09].  This package provides a set of independent plotting geometries and aesthetics that can be built piecewise and is a departure from other graphics packages that represent a collection of special cases that limit the freedom of the analyst.  In bioassessment, ggplot2 can be used both in an exploratory role during the development phase and also to create publication quality graphics.  More importantly, this package provides the building blocks to create a data visualization to convey important components of a bioassessment product to managers and stakeholders.   

Bioassessment data are inherently spatial and recent package development has greatly improved the ability to analyse and map geospatial data in R.  These tools can readily communicate the spatial context of bioassessment products to managers and stakeholders by mapping index or condition scores to stream flow networks, watersheds, and ecoregions, both for high-level planning and site-specific evaluations.  The simple features package [@Pebesma18] was first released in 2016 and has quickly become the most accessible means of working with spatial information in R.  The simple features package uses principles of data storage that parallel those from the tidyverse by representing spatial objects in a tidy and tabular format.  This facilitates analysis by presenting complex spatial structures in an easily readable format that can integrated in workflows with existing packages.  This allows the researcher to use a workflow that is focused in a single environment, rather than using separate software for statistical and geospatial analysis.  This reduces the likelihood of losing information or introducing analysis errors as the workflow is more transparent in a single environment.

Other existing R packages can be used to develop statistical models of bioassessment data that are a necessary component of many analyses.  Random forest models have been used to develop predictive bioassessment indices that compare observed taxa to modelled expectations (i.e., O/E indices).  The randomForest package [@Liaw02] uses an ensemble learning approach that is robust to complex, non-linear relationships and interactions between variables.  These models are particularly useful with large, regional datasets that describe natural and anthropogenic gradients in condition.  Many other modelling packages are available in R that can support index development, such as exploratory analyses to evaluate biological response or identifying significant associations of organisms with stressor gradients.  The nlme package can be used to create non-linear mixed effect models that are more flexible than standard regression approaches [@Pinheiro18].  The nlme package can develop models for nested sampling designs, such as repeat visits to sample sites or otherwise confounding variables that contribute information but are not unique observations.  The mgcv package provides similar functionality as nlme, but uses an additive modelling approach where invididual effects can be evaluated as the sum of smoothed terms [@Wood17].  

Currently, only a few existing R packages have been developed speicifically for bioassessment.  For example, the TITAN2 package can be used to developed quantitative evidence of taxon-specific changes in abundance and occurrence across environmental gradients [@Baker15].  Results from this package can support exploratory analysis for developing bioassessment products, such as identifying indicator species.  The results can be also be used post hoc to evaluate potential response of a biological index with changing environmental conditons, such as proposed management actions to improve aquatic habitat.  Alternatively, the indicspecies package provides similar functionality but is based only on species occurrence or abundance matrices across sites.  This package can be used to identify species that occur at particular sites if continuous environmental data are unavailable, such as those that are representative of reference conditions.  Finally, the vegan package has been a staple among community ecologists for multivariate analyses in R, such as clustering and ordination. This package has value for bioassessment as an exploratory tool with a variety of applications, such as analyses that identify comparable assessment sites that minimize natural variation [@Beck13].

Although the R network includes over 10000 user contributed packages, the most underutilized aspect of this software for bioassessment is the creation of new packages to support implementation.  Several tools have been developed and published in the last five years that simplify the process of creating new packages in R [@Wickham15;@Wickham18].  The increasing popularity in the environmental sciences of online repositories for hosting code and software, such as GitHub, also provides a venue for sharing tehse packages.  The advantages of creating and sharing R packages that are specific to bioassessment applications are important for several reasons.  First, an R package creates a compartmentalized set of instructions developed during the technical research phase that can be executed by anyone with access to a computer.  This allows the developer to include important technical elements required for the execution of a bioassessment product within the package, while allowing the end user to focus on how the output can be used to inform decision-making.  R packages also require explicit documentation of the functions and data requirements.  As such, package users will not only have access to underlying code but also understand the why and what for different package functions.  Detailed vignettes can be included in plain language to describe how to use the package.     

Finally, R can also be leveraged to create interactive applications that deliver bioassessment products to stakeholders and managers in entirely novel contexts.  In particular, the shiny package was first released for R in 2012 and provides programming tools built around concepts of reactivity, where inputs and outputs can be modified in real time.  A Shiny application is an interactive user interface that is developed with R code, but is a standalone product that can used without any programming experience.  These applications are deployed online and can extend the reach of bioassessment tools to those that require the information for decision-making but otherwise do not have the time or resources to learn R.  Shiny applications can also be easily linked to other R packages.  For example, a Shiny website could be created for users to upload raw data and bioassessment scores could be estimated and reported using an R package developed externally.  This can extend the accessibility of a bioassessment product while maintaining the technical integrity of the original tool.  Moreover, shiny applications are completely customizable and can be tailored to the specific needs of any users.  This distinction separates shiny from other web-based analysis platforms.    

# Case studies of open science in practice

# Limitations and solutions

# References


# Figures 

```{r basicflow, fig.cap = 'A simplified workflow of the open science paradigm (adapted from @Hampton15).  All aspects of the research process, from the conception of an idea to publishing a product, can be enhanced using open science tools.  The workflow is iterative where products are continually improved through collaborations facilitated through discovery and reproducibility of open data.'}
knitr::include_graphics('figs/basicflow.png')
```

```{r closedopen, fig.cap = 'Examples of (a) closed and (b) open approaches for bioassessment applications. The oval box in each subfigure represents the technical steps of the individual researcher for developing the product, the regulatory and stakeholder boxes indicate those that require or motivate the creation of bioassessment products, the gray boxes indicate sources of external information (data and guidance documents) as input into the technical process, and the open text indicates open components of the planning or implementation phase of a bioassessment product. Figures were adapted from @Hampton15.'}
knitr::include_graphics('figs/closedopen.png')
